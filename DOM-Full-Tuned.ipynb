{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this code, I work on the output from QUaltrics which is in XLSX and numeric format. This data covers the responses of 10 online questionnaires\n",
    "#that participants had to answer. Here are the list of all questionnaires. \n",
    "#1. Trier inventory chronic stress (TICS)\n",
    "#2. Social value orientation (SVO)\n",
    "#3. Big Five inventory (10 items-BFI 10)\n",
    "#4. behavioral inhibition/Approach system(BIS/BAS)\n",
    "#5. behavioral inhibition system 15 items (BIS 15)\n",
    "#6. Cognitive reflection test(CRT)\n",
    "#7. Perspective tasking test (from the paper-Soutschek et al 2016)\n",
    "#8. Morningness-Eveningness Questionnaire (MEQ)\n",
    "#9. State trait anxiety (STAI)\n",
    "#10. Social desirability (SDS-17)\n",
    "\n",
    "#for each questionnaire there is a certain rules of calculations. Based on these roles I try to calculate the answer of particiapnts for each \n",
    "# questionnaire and create a proceed data for our final statistical analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# Load raw data from online questionnaire\n",
    "raw_onlinefb = pd.read_excel(\"online_douman_raw.xlsx\", engine='openpyxl')\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "raw_onlinefb = raw_onlinefb.drop(0).drop(columns=[\n",
    "    'EndDate', 'Status', 'IPAddress', 'Finished', 'RecipientLastName', 'RecordedDate', 'ResponseId',\n",
    "    'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude',\n",
    "    'LocationLongitude', 'UserLanguage'])\n",
    "\n",
    "# Keep only completed surveys from anonymous and qr distribution channels\n",
    "raw_onlinefb = raw_onlinefb[raw_onlinefb['Progress'] == 100]\n",
    "raw_onlinefb = raw_onlinefb[raw_onlinefb['DistributionChannel'].isin(['anonymous', 'qr'])]\n",
    "\n",
    "# Drop rows with empty VP codes\n",
    "raw_onlinefb.dropna(subset=['Q132_1'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trier inventory chronic stress (TICS)\n",
    "# TICS QS columns\n",
    "df_tics = ['Q2_1', 'Q2_2', 'Q2_3', 'Q2_4', 'Q2_5', 'Q111_1', 'Q111_2', 'Q111_3', 'Q111_4', 'Q111_5',\n",
    "           'Q76_1', 'Q76_2', 'Q76_3', 'Q76_5', 'Q110_1', 'Q110_2', 'Q110_3', 'Q110_4',\n",
    "           'Q110_5', 'Q77_1', 'Q77_2', 'Q77_3', 'Q77_4', 'Q77_5', 'Q112_1',\n",
    "           'Q112_2', 'Q112_3', 'Q112_4', 'Q112_5', 'Q78_1', 'Q78_2', 'Q78_3',\n",
    "           'Q78_4', 'Q78_5', 'Q113_1', 'Q113_2', 'Q113_3', 'Q113_4',\n",
    "           'Q113_5', 'Q79_1', 'Q79_2', 'Q79_3', 'Q79_4', 'Q114_1', 'Q114_2',\n",
    "           'Q114_3', 'Q114_4', 'Q114_5', 'Q80_1', 'Q80_3',\n",
    "           'Q80_4', 'Q80_5', 'Q115_1', 'Q115_2', 'Q115_3', 'Q115_4',\n",
    "           'Q115_5']\n",
    "\n",
    "# Control questions\n",
    "control_qs = ['Q76_4', 'Q79_5', 'Q80_2']\n",
    "control_1 = [('True' if i == 4 else 'False') for i in raw_onlinefb[control_qs[0]]]\n",
    "control_2 = [('True' if i == 1 else 'False') for i in raw_onlinefb[control_qs[1]]]\n",
    "control_3 = [('True' if i == 2 else 'False') for i in raw_onlinefb[control_qs[2]]]\n",
    "\n",
    "# TICS subgroups\n",
    "WOL, SO, PP, WD, EDW, LSR, ST, SI, CW = [1, 4, 44, 54, 17, 27, 38, 50], [49, 57, 7, 19, 28, 39], [8, 12, 14, 22, 30, 23, 32, 40, 43], [5,10,13,41,21,37,48,53],[3,47,20,24,35,55],[2,18,31,46],[6,33,15,26,45,52],[29,34,11,42,51,56],[9,16,25,36]\n",
    "\n",
    "# Convert label of tic cols into numbers\n",
    "# with showing they belong to which subcategory of tics\n",
    "tics_num=[]\n",
    "tics_dict = dict(zip(df_tics, tics_num))\n",
    "raw_onlinefb = raw_onlinefb.rename(columns={\n",
    "    'Q2_1': '1_WOL', 'Q2_2': '2_LSR', 'Q2_3': '3_EDW', 'Q2_4': '4_WOL', 'Q2_5': '5_WD',\n",
    "    'Q111_1': '6_ST', 'Q111_2': '7_SO', 'Q111_3': '8_PP', 'Q111_4': '9_CW', 'Q111_5': '10_WD',\n",
    "    'Q76_1': '11_SI', 'Q76_2': '12_PP', 'Q76_3': '13_WD', 'Q76_5': '14_PP',\n",
    "    'Q110_1': '15_ST', 'Q110_2': '16_CW', 'Q110_3': '17_WOL', 'Q110_4': '18_LSR', 'Q110_5': '19_SO',\n",
    "    'Q77_1': '20_EDW', 'Q77_2': '21_WD', 'Q77_3': '22_PP', 'Q77_4': '23_PP', 'Q77_5': '24_EDW',\n",
    "    'Q112_1': '25_CW', 'Q112_2': '26_ST', 'Q112_3': '27_WOL', 'Q112_4': '28_SO', 'Q112_5': '29_SI',\n",
    "    'Q78_1': '30_PP', 'Q78_2': '31_LSR', 'Q78_3': '32_PP', 'Q78_4': '33_ST', 'Q78_5': '34_SI',\n",
    "    'Q113_1': '35_EDW', 'Q113_2': '36_CW', 'Q113_3': '37_WD', 'Q113_4': '38_WOL', 'Q113_5': '39_SO',\n",
    "    'Q79_1': '40_PP', 'Q79_2': '41_WD', 'Q79_3': '42_SI', 'Q79_4': '43_PP',\n",
    "    'Q114_1': '44_WOL', 'Q114_2': '45_ST', 'Q114_3': '46_LSR', 'Q114_4': '47_EDW', 'Q114_5': '48_WD',\n",
    "    'Q80_1': '49_SO', 'Q80_3': '50_WOL', 'Q80_4': '51_SI', 'Q80_5': '52_ST',\n",
    "    'Q115_1': '53_WD', 'Q115_2': '54_WOL', 'Q115_3': '55_EDW', 'Q115_4': '56_SI', 'Q115_5': '57_SO'})\n",
    "\n",
    "raw_onlinefb['TICS'] = raw_onlinefb[tics_num].sum(axis=1)\n",
    "raw_onlinefb['TICS_control1'] = control_1\n",
    "raw_onlinefb['TICS_control2'] = control_2\n",
    "raw_onlinefb['TICS_control3'] = control_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Social value orientation (SVO)\n",
    "\n",
    "\n",
    "# Function to process SVO questions\n",
    "def process_svo_question(raw_data, question, orientations):\n",
    "    return [orientations.get(x, 'None') for x in raw_data[question]]\n",
    "\n",
    "# SVO data preparation\n",
    "svo_cols = ['Q92_1', 'Q103_1', 'Q102_1', 'Q101_1', 'Q100_1', 'Q99_1', 'Q98_1', 'Q97_1', 'Q96_1']\n",
    "svo_new_cols = ['svo_1', 'svo_2', 'svo_3', 'svo_4', 'svo_5', 'svo_6', 'svo_7', 'svo_8', 'svo_9']\n",
    "orientation_orders = [\n",
    "    {1: 'ind', 2: 'Com', 3: 'pro'},\n",
    "    {1: 'Com', 2: 'pro', 3: 'ind'},\n",
    "    {1: 'pro', 2: 'ind', 3: 'Com'}\n",
    "]\n",
    "\n",
    "# Process and rename SVO columns\n",
    "for svo_col, new_col, orientations in zip(svo_cols, svo_new_cols, orientation_orders * 3):\n",
    "    raw_onlinefb[new_col] = process_svo_question(raw_onlinefb, svo_col, orientations)\n",
    "    raw_onlinefb = raw_onlinefb.rename(columns={svo_col: new_col})\n",
    "\n",
    "# Count occurrences of prosocial, individualistic, and competitive orientations\n",
    "raw_onlinefb[\"prosocial\"] = raw_onlinefb.isin(['pro']).sum(axis='columns')\n",
    "raw_onlinefb[\"individualistic\"] = raw_onlinefb.isin(['ind']).sum(axis='columns')\n",
    "raw_onlinefb[\"competetive\"] = raw_onlinefb.isin(['Com']).sum(axis='columns')\n",
    "\n",
    "# Determine SVO_Final based on the count of orientations\n",
    "conditions = [\n",
    "    (raw_onlinefb[\"prosocial\"] >= 6),\n",
    "    (raw_onlinefb[\"individualistic\"] >= 6),\n",
    "    (raw_onlinefb[\"competetive\"] >= 6)\n",
    "]\n",
    "values = [\"prosocial\", \"individualistic\", \"competetive\"]\n",
    "raw_onlinefb['SVO_Final'] = np.select(conditions, values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. behavioral inhibition/Approach system(BIS/BAS)\n",
    "# Prepare data for analysis of BIS/BAS\n",
    "bis_bas=['Q75_1','Q75_2','Q75_3','Q75_4','Q75_5','Q75_6','Q116_1',\n",
    "         'Q116_2','Q116_3',\n",
    "         'Q116_4','Q116_5','Q116_6',\n",
    "         'Q117_1','Q117_2','Q117_3','Q117_4',\n",
    "         'Q117_5','Q117_6','Q118_1','Q118_2','Q118_3','Q118_4','Q118_5',\n",
    "         'Q118_6']\n",
    "\n",
    "categories = {\n",
    "    'BIS_Total': [2, 8, 13, 16, 19, 22, 24],\n",
    "    'BAS_drive': [3, 9, 12, 21],\n",
    "    'BAS_FUN': [5, 10, 15, 20],\n",
    "    'BAS_rewards': [4, 7, 14, 18, 23],\n",
    "    'Filler': [1, 6, 11, 17]\n",
    "}\n",
    "\n",
    "# Create a list of category labels\n",
    "BIS_BAS_num = [f\"{i}_{category}\" for i in range(1, 25) for category, items in categories.items() if i in items]\n",
    "\n",
    "# Create a dictionary to re-label the raw column names from raw data for BIS/BAS test\n",
    "bisbas_dic = dict(zip(bis_bas, BIS_BAS_num))\n",
    "\n",
    "# Rename columns in the raw_onlinefb DataFrame\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=bisbas_dic)\n",
    "\n",
    "# Reverse scoring for specific columns\n",
    "reverse_scoring = {'2_BIS_Total': {1: 4, 2: 3, 3: 2, 4: 1}, '22_BIS_Total': {1: 4, 2: 3, 3: 2, 4: 1}}\n",
    "raw_onlinefb = raw_onlinefb.replace(reverse_scoring)\n",
    "\n",
    "# Compute the sums for each category\n",
    "for category, items in categories.items():\n",
    "    if category != 'Filler':\n",
    "        raw_onlinefb[f'{category}_qs'] = raw_onlinefb[[f\"{i}_{category}\" for i in items]].sum(axis=1)\n",
    "\n",
    "# Prepare BIS_15 questions for data analysis\n",
    "Bis_15_raw=['Q82_1','Q82_2','Q82_3','Q82_4','Q82_5','Q85_1','Q85_2','Q85_3','Q85_4','Q85_5','Q86_1',\n",
    "'Q86_2','Q86_3','Q86_4','Q86_5']\n",
    "\n",
    "bis_15_categories = {\n",
    "    'BIS-15-NPI': [1, 5, 7, 8, 15],\n",
    "    'BIS-15-MI': [2, 10, 12, 13, 9],\n",
    "    'BIS-15-ABI': [14, 6, 4, 3, 11]\n",
    "}\n",
    "\n",
    "# Create a list of BIS_15 labels\n",
    "BIS_15_lis = [f\"{i}-{category}\" for i in range(1, 16) for category, items in bis_15_categories.items() if i in items]\n",
    "# Synchronize raw data with edited column names\n",
    "bis15_dic = dict(zip(Bis_15_raw, BIS_15_lis))\n",
    "\n",
    "# Rename the BIS-15 columns\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=bis15_dic)\n",
    "\n",
    "# Reverse scoring for specific questions\n",
    "reverse_map = {1: 4, 2: 3, 3: 2, 4: 1}\n",
    "reverse_qs = ['13-BIS-15-MI', '15-BIS-15-NPI', '1-BIS-15-NPI', '7-BIS-15-NPI', '4-BIS-15-ABI']\n",
    "for q in reverse_qs:\n",
    "    raw_onlinefb[q] = raw_onlinefb[q].map(reverse_map)\n",
    "bis_15_mi=['2-BIS-15-MI','9-BIS-15-MI','10-BIS-15-MI','12-BIS-15-MI','13-BIS-15-MI']\n",
    "bis_15_npi=['1-BIS-15-NPI','5-BIS-15-NPI','7-BIS-15-NPI','8-BIS-15-NPI','15-BIS-15-NPI']\n",
    "bis_15_abi=['3-BIS-15-ABI','4-BIS-15-ABI','6-BIS-15-ABI','11-BIS-15-ABI','14-BIS-15-ABI']\n",
    "BIS_15_total=['2-BIS-15-MI','9-BIS-15-MI','10-BIS-15-MI','12-BIS-15-MI','13-BIS-15-MI',\n",
    "       '1-BIS-15-NPI','5-BIS-15-NPI','7-BIS-15-NPI','8-BIS-15-NPI','15-BIS-15-NPI',\n",
    "       '3-BIS-15-ABI','4-BIS-15-ABI','6-BIS-15-ABI','11-BIS-15-ABI','14-BIS-15-ABI']\n",
    "# Calculate scores for BIS-15 subcategories and total\n",
    "categories = {\n",
    "    'BIS_15_MI': bis_15_mi,\n",
    "    'BIS_15_NPI': bis_15_npi,\n",
    "    'BIS_15_ABI': bis_15_abi,\n",
    "    'BIS_15_total': BIS_15_total}\n",
    "\n",
    "for cat, items in categories.items():\n",
    "    raw_onlinefb[cat] = raw_onlinefb[items].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_onlinefb.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Big Five inventory (10 items-BFI 10)\n",
    "# BFI data preparation\n",
    "BFI_Raw = ['Q135_1', 'Q135_2', 'Q135_3', 'Q135_4', 'Q135_5', 'Q136_1', 'Q136_2', 'Q136_3', 'Q136_4', 'Q136_5']\n",
    "dimensions = {'N': [4, 9], 'E': [1, 6], 'O': [5, 10], 'A': [2, 7], 'C': [3, 8]}\n",
    "BFI_list = [f'{i}-BFI_{dim}' for i in range(1, 11) for dim, questions in dimensions.items() if i in questions]\n",
    "\n",
    "BFI_dic = dict(zip(BFI_Raw, BFI_list))\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=BFI_dic)\n",
    "\n",
    "reverse_scores = {'1-BFI_E', '3-BFI_C', '4-BFI_N', '5-BFI_O', '7-BFI_A'}\n",
    "for col in reverse_scores:\n",
    "    raw_onlinefb[col] = raw_onlinefb[col].map({1: 5, 2: 4, 3: 3, 4: 2, 5: 1})\n",
    "\n",
    "for dim, questions in dimensions.items():\n",
    "    cols = [f'{q}-BFI_{dim}' for q in questions]\n",
    "    raw_onlinefb[f'BFI_{dim}'] = raw_onlinefb[cols].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#5. Cognitive reflection test(CRT)\n",
    "\n",
    "crt_raw = ['Q88_1', 'Q89_1', 'Q90_1']\n",
    "crt_columns = ['CRT_ball', 'CRT_machine', 'CRT_lake']\n",
    "crt_answers = [['5', '0,05', '5 cent'], ['5', '5 Minuten'], ['47', '47 Tage']]\n",
    "\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=dict(zip(crt_raw, crt_columns)))\n",
    "\n",
    "for column, answers in zip(crt_columns, crt_answers):\n",
    "    raw_onlinefb[column] = raw_onlinefb[column].apply(lambda x: 'True' if x in answers else 'False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#6. State trait anxiety (STAI)\n",
    "# Prepare STAI questions for data analysis\n",
    "# There are two sets of questions, each containing 20 questions\n",
    "\n",
    "# # STAI data preparation\n",
    "stais_raw = [f'Q67_{i}' for i in range(1, 6)] + [f'Q119_{i}' for i in range(1, 6)] + [f'Q120_{i}' for i in range(1, 6)] + [f'Q121_{i}' for i in range(1, 6)] + [f'Q71_{i}' for i in range(1, 6)] + [f'Q122_{i}' for i in range(1, 6)] + [f'Q123_{i}' for i in range(1, 6)] + [f'Q124_{i}' for i in range(1, 6)]\n",
    "nums = [f'{i}-stai' for i in range(1, 41)]\n",
    "\n",
    "raw_onlinefb.rename(columns=dict(zip(stais_raw, nums)), inplace=True)\n",
    "\n",
    "reversed_qs = [f'{i}-stai' for i in [1, 2, 5, 8, 10, 11, 15, 16, 19, 20, 21, 23, 26, 27, 30, 33, 34, 36, 39]]\n",
    "raw_onlinefb[reversed_qs] = raw_onlinefb[reversed_qs].replace({1: 4, 2: 3, 3: 2, 4: 1})\n",
    "\n",
    "raw_onlinefb['stai_total'] = raw_onlinefb[reversed_qs].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#7. Social desirability (SDS-17)\n",
    "# Prepare raw data from SDS 17\n",
    "raw_sds = ['Q33', 'Q65', 'Q49', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60', 'Q61', 'Q62', 'Q63', 'Q64']\n",
    "\n",
    "# Generate new column names\n",
    "sds_num = [f\"{i}-SDS17\" for i in range(1, 18)]\n",
    "\n",
    "# Create a dictionary to map raw column names to new column names\n",
    "sds17_dic = dict(zip(raw_sds, sds_num))\n",
    "\n",
    "# Rename the columns from raw to new column names\n",
    "raw_onlinefb.rename(columns=sds17_dic, inplace=True)\n",
    "\n",
    "# Define SDS column names\n",
    "sds_cols = sds_num\n",
    "\n",
    "# Calculate the total score for SDS17 by counting the number of 1's (True) in each row\n",
    "raw_onlinefb['sds_total'] = (raw_onlinefb[sds_cols] == 1).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#8. Morningness-Eveningness Questionnaire (MEQ)\n",
    "\n",
    "\n",
    "# Prepare raw data for MEQ\n",
    "cs = [14, 17, 19, 24, 21]\n",
    "es = [1, 2, 5, 7, 9, 11]\n",
    "ec = [10, 15, 18, 20, 22, 23, 25]\n",
    "cc = [3, 4, 6, 8, 13]\n",
    "meq_raw_cols = ['Q12', 'Q13', 'Q14', 'Q15', 'Q16']\n",
    "meq_new_cols = ['meq-1', 'meq-2', 'meq-3', 'meq-4', 'meq-5']\n",
    "meq_col_mapping = dict(zip(meq_raw_cols, meq_new_cols))\n",
    "\n",
    "# Rename MEQ columns\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=meq_col_mapping)\n",
    "\n",
    "# Reverse the second MEQ question\n",
    "raw_onlinefb['meq-2'] = raw_onlinefb['meq-2'].map({4:1, 3:2, 2:3, 1:4})\n",
    "\n",
    "# Calculate MEQ total score\n",
    "raw_onlinefb['meq_total'] = raw_onlinefb[meq_new_cols].sum(axis=1)\n",
    "\n",
    "# Prepare E-Scale data\n",
    "raw_cols = ['Q138_1', 'Q138_2', 'Q138_3', 'Q138_4', 'Q138_5', 'Q140_1', 'Q140_2', 'Q140_3', 'Q140_4', 'Q140_5', 'Q141_1',\n",
    "            'Q141_2', 'Q141_3', 'Q141_4', 'Q141_5', 'Q142_1', 'Q142_2', 'Q142_3', 'Q142_4', 'Q142_5', 'Q143_1', 'Q143_2', 'Q143_3', \n",
    "            'Q143_4', 'Q143_5']\n",
    "\n",
    "e_scale = [f\"{i}-escale_{'cs' if i in cs else 'es' if i in es else 'ec' if i in ec else 'cc'}\" for i in range(1, 26)]\n",
    "\n",
    "escale_dict = dict(zip(raw_cols, e_scale))\n",
    "\n",
    "# Rename E-Scale columns\n",
    "raw_onlinefb = raw_onlinefb.rename(columns=escale_dict)\n",
    "\n",
    "# Reverse the 20th E-Scale question\n",
    "raw_onlinefb['20-escale_ec'] = raw_onlinefb['20-escale_ec'].map({1:5, 2:4, 3:3, 4:2, 5:1})\n",
    "\n",
    "# Calculate E-Scale total score\n",
    "raw_onlinefb['e-scale_total'] = raw_onlinefb[e_scale].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Perspective tasking test (from the paper-Soutschek et al 2016)\n",
    "#to remove the empty cols of avatar test and bringing all under each other\n",
    "# i need to add 2 to empty cells in col Q500\n",
    "# then only for rows of q500 that are 2 and if 1_Q194_First Click is empty \n",
    "#remove the cols from 1_Q194_First Click to 1_Q196_First Click\n",
    "\n",
    "#add 2 to Q500\n",
    "raw_onlinefb.Q500.fillna(2,inplace=True)\n",
    " \n",
    "\n",
    "# Replacing empty string with np.NaN\n",
    "\n",
    "raw_onlinefb = raw_onlinefb.replace('', np.nan)\n",
    "df_left=raw_onlinefb[(~raw_onlinefb['1_Q194_First Click'].isnull())&(raw_onlinefb['Q500']==2)]\n",
    "#remove the unwanted cols from df_left\n",
    "\n",
    "df_left.drop(columns=df_left.loc[:,'1_Q196_First Click':'64_Q193'], axis=1,inplace=True)\n",
    "#creating two separated dfs to get rid of duplicate cols\n",
    "df_right=raw_onlinefb[(raw_onlinefb['1_Q194_First Click'].isnull())&(raw_onlinefb['Q500']==2)]\n",
    "\n",
    "#remove the unwanted cols from df_right\n",
    "df_right.drop(columns=df_right.loc[:,'Q500_1_TEXT':'64_Q175'], axis=1,inplace=True)\n",
    "\n",
    "#df_left name of cols \n",
    "col_df_left=df_left.loc[:,'1_Q194_First Click':'64_Q175'].columns.to_list()\n",
    "#df_right name of cols\n",
    "col_df_right=df_right.loc[:,'1_Q196_First Click':'64_Q193'].columns.to_list()\n",
    "#make dict for both cols names\n",
    "dict_col_name=dict(zip(col_df_right,col_df_left))  \n",
    "#rename the df_right specific col names by df_left col names\n",
    "df_right=df_right.rename(dict_col_name,axis=1)\n",
    "#add the information which order of perspective they did: left or right\n",
    "df_left['perspective-order']='left'\n",
    "df_right['perspective-order']='right'\n",
    "#encode the right and wrong questions\n",
    "#for now I coded not answered 'NONE'qs as wrong answered question\n",
    "#left order 5=stimmt nicht 端berein 4=stimmt 端berein \n",
    "#right order 4=stimmt nicht 端berein , 5=stimmt 端berein \n",
    "#questions and correct answers\n",
    "\n",
    "#question_left_5 as correct answer\n",
    "ql5c=['1_Q175','5_Q175','7_Q175','8_Q175','13_Q175','14_Q175','18_Q175','19_Q175','21_Q175','22_Q175','23_Q175','30_Q175','31_Q175','35_Q175'\n",
    ",'36_Q175','38_Q175','39_Q175','40_Q175','41_Q175','43_Q175','46_Q175','48_Q175','51_Q175','52_Q175','53_Q175','55_Q175','56_Q175','57_Q175',\n",
    "'59_Q175','60_Q175','63_Q175','64_Q175']\n",
    "df_left[ql5c]= np.where(df_left[ql5c]==5, 0, 1)\n",
    "#question_right_4 as correct answer\n",
    "qr4c=['1_Q175','5_Q175','7_Q175','8_Q175','13_Q175','14_Q175','18_Q175','19_Q175','21_Q175','22_Q175','23_Q175','30_Q175','31_Q175','35_Q175'\n",
    ",'36_Q175','38_Q175','39_Q175','40_Q175','41_Q175','43_Q175','46_Q175','48_Q175','51_Q175','52_Q175','53_Q175','55_Q175','56_Q175','57_Q175',\n",
    "'59_Q175','60_Q175','63_Q175','64_Q175']\n",
    "df_right[qr4c]= np.where(df_right[qr4c]==4, 0, 1)\n",
    "#question_left_4 as correct answer\n",
    "ql4c=['2_Q175','3_Q175','4_Q175','6_Q175','9_Q175','10_Q175','11_Q175','12_Q175','15_Q175','16_Q175','17_Q175','20_Q175','24_Q175','25_Q175'\n",
    ",'26_Q175','27_Q175','28_Q175','29_Q175','32_Q175','33_Q175','34_Q175','37_Q175','42_Q175','44_Q175','45_Q175','47_Q175','49_Q175','50_Q175',\n",
    "'54_Q175','58_Q175','61_Q175','62_Q175']\n",
    "df_left[ql4c]= np.where(df_left[ql4c]==4, 0, 1)\n",
    "#question_right_5 as correct answer\n",
    "qr5c=['2_Q175','3_Q175','4_Q175','6_Q175','9_Q175','10_Q175','11_Q175','12_Q175','15_Q175','16_Q175','17_Q175','20_Q175','24_Q175','25_Q175'\n",
    ",'26_Q175','27_Q175','28_Q175','29_Q175','32_Q175','33_Q175','34_Q175','37_Q175','42_Q175','44_Q175','45_Q175','47_Q175','49_Q175','50_Q175',\n",
    "'54_Q175','58_Q175','61_Q175','62_Q175']\n",
    "df_right[qr5c]= np.where(df_right[qr5c]==5, 0, 1)\n",
    "# i need to create four groups 1. self congurent (sc) 2. self incongruent(si) 3.other congruent(oc) 4.other incongruent (oi)\n",
    "sc=['10_Q175','12_Q175','15_Q175','16_Q175','20_Q175','25_Q175','26_Q175','27_Q175','28_Q175','33_Q175','34_Q175','42_Q175','47_Q175','49_Q175'\n",
    ",'61_Q175','62_Q175']\n",
    "si=['1_Q175','7_Q175','14_Q175','18_Q175','21_Q175','31_Q175','36_Q175','38_Q175','41_Q175','46_Q175','51_Q175','56_Q175','59_Q175','60_Q175'\n",
    ",'63_Q175','64_Q175']\n",
    "oc=['2_Q175','3_Q175','4_Q175','6_Q175','9_Q175','11_Q175','17_Q175','24_Q175','29_Q175','32_Q175','37_Q175','44_Q175','45_Q175','50_Q175'\n",
    ",'54_Q175','58_Q175']\n",
    "oi=['5_Q175','8_Q175','13_Q175','19_Q175','22_Q175','23_Q175','30_Q175','35_Q175','39_Q175','40_Q175','43_Q175','48_Q175','52_Q175','53_Q175'\n",
    ",'55_Q175','57_Q175']\n",
    "# remove trials 3 and 63 due to wrong link of picture for participants before the date 17.10.2022\n",
    "#append both dfs\n",
    "df_left.drop('Q500_1_TEXT', inplace=True,axis=1)\n",
    "df = pd.concat([df_left, df_right], ignore_index=True)\n",
    "\n",
    "#column for sum of sc\n",
    "df['self_congurent']= df.apply(lambda row: row[sc].sum(),axis=1)\n",
    "df['self_congurent']=(16-df['self_congurent'])/16\n",
    "#column for sum of si\n",
    "df['self_incongurent']=df.apply(lambda row: row[si].sum(),axis=1)\n",
    "df['self_incongurent']=(16-df['self_incongurent'])/16\n",
    "#column for sum of oc\n",
    "df['other_congurent']=df.apply(lambda row: row[oc].sum(),axis=1)\n",
    "df['other_congurent']=(16-df['other_congurent'])/16\n",
    "#column for sum of oi\n",
    "df['other_incongurent']=df.apply(lambda row: row[oi].sum(),axis=1)\n",
    "df['other_incongurent']=(16-df['other_incongurent'])/16\n",
    "#calculate the incongurent! if value is >0 means self incongurent and if <0 other ingurent and 0 means no ingurennt\n",
    "df['perspective']=(df['self_incongurent']-df['self_congurent'])-(df['other_incongurent']-df['other_congurent'])\n",
    "\n",
    "\n",
    "\n",
    "df.rename(columns={'StartDate':'Date','Q132_1':'Vp-Code'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "\n",
    "df.rename(columns={\n",
    "'StartDate': 'Date',\n",
    "'Q132_1': 'Vp-Code'\n",
    "}, inplace=True)\n",
    "\n",
    "#Define the columns to be exported for statistical analysis\n",
    "\n",
    "cols_wanted = [\n",
    "'Date', 'Duration (in seconds)', 'Vp-Code', 'TICS', 'TICS_control1', 'TICS_control2', 'TICS_control3', 'SVO_Final', 'BIS_Total_qs',\n",
    " 'BAS_drive_qs','BAS_FUN_qs','BAS_rewards_qs', 'BIS_15_MI', 'BIS_15_NPI', 'BIS_15_ABI',\n",
    "'BIS_15_total', 'BFI_N', 'BFI_E', 'BFI_O', 'BFI_A', 'BFI_C', 'CRT_ball', 'CRT_machine', 'CRT_lake', 'stai_total', 'sds_total',\n",
    "'meq_total', 'e-scale_total', 'perspective'\n",
    "]\n",
    "\n",
    "#Select the desired columns from the dataframe\n",
    "\n",
    "df = df[cols_wanted]\n",
    "\n",
    "#Update the Vp-Code for a specific participant\n",
    "\n",
    "df.loc[df['Vp-Code'] == 'ANPE07B', 'Vp-Code'] = 'HETO16B'\n",
    "\n",
    "#Sort the dataframe by Vp-Code\n",
    "\n",
    "df.sort_values(by='Vp-Code', inplace=True)\n",
    "\n",
    "#Export the edited dataframe to an Excel file\n",
    "\n",
    "df.to_excel('df_online_DOM.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
